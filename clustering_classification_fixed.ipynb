{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Classification Fixed Notebook\n",
    "\n",
    "This notebook performs clustering and classification on the preprocessed dataset.\n",
    "- Load final_dataset.csv.\n",
    "- Feature selection using RF feature importance.\n",
    "- Clustering with KMeans, determine optimal k using elbow and silhouette.\n",
    "- Add cluster labels as feature.\n",
    "- Classification with RF and XGB, evaluate metrics.\n",
    "- Recommendations: Top-3 tree species per cluster.\n",
    "- Save models to models/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/Users/godishalarishi/AML-tree/final_dataset.csv')\n",
    "print('Dataset shape:', df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Assume target is 'tree species' (encoded)\n",
    "target = 'tree species'\n",
    "features = [col for col in df.columns if col != target]\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split for classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Use Random Forest feature importance to select top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance with RF\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot top 10\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(10), importances[indices][:10], align='center')\n",
    "plt.xticks(range(10), [features[i] for i in indices][:10], rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Select top 10 features\n",
    "top_features = [features[i] for i in indices][:10]\n",
    "X_selected = X[top_features]\n",
    "X_train_sel = X_train[top_features]\n",
    "X_test_sel = X_test[top_features]\n",
    "\n",
    "print('Selected features:', top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Use KMeans, determine optimal k with elbow and silhouette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_selected)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_selected, kmeans.labels_))\n",
    "\n",
    "# Plot elbow\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_range, inertias, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "\n",
    "# Plot silhouette\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_range, silhouettes, marker='o')\n",
    "plt.title('Silhouette Score')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()\n",
    "\n",
    "# Choose optimal k, e.g., k=4 based on plots\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_selected)\n",
    "\n",
    "# Add cluster as feature\n",
    "df['cluster'] = clusters\n",
    "X_selected['cluster'] = clusters\n",
    "X_train_sel['cluster'] = clusters[:len(X_train_sel)]\n",
    "X_test_sel['cluster'] = clusters[len(X_train_sel):]\n",
    "\n",
    "print('Optimal k:', optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Train RF and XGB with SMOTE if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "print('Class distribution:', y_train.value_counts())\n",
    "\n",
    "# Apply SMOTE if imbalanced\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_sel, y_train)\n",
    "\n",
    "# RF\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_sm, y_train_sm)\n",
    "y_pred_rf = rf_clf.predict(X_test_sel)\n",
    "y_prob_rf = rf_clf.predict_proba(X_test_sel)\n",
    "\n",
    "print('RF Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print('RF F1:', f1_score(y_test, y_pred_rf, average='weighted'))\n",
    "print('RF ROC-AUC:', roc_auc_score(label_binarize(y_test, classes=np.unique(y)), y_prob_rf, multi_class='ovr', average='weighted'))\n",
    "\n",
    "# XGB\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb_clf.fit(X_train_sm, y_train_sm)\n",
    "y_pred_xgb = xgb_clf.predict(X_test_sel)\n",
    "y_prob_xgb = xgb_clf.predict_proba(X_test_sel)\n",
    "\n",
    "print('XGB Accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
    "print('XGB F1:', f1_score(y_test, y_pred_xgb, average='weighted'))\n",
    "print('XGB ROC-AUC:', roc_auc_score(label_binarize(y_test, classes=np.unique(y)), y_prob_xgb, multi_class='ovr', average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "Top-3 tree species per cluster based on probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster, get top 3 predicted species\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = X_selected[X_selected['cluster'] == cluster]\n",
    "    if not cluster_data.empty:\n",
    "        probs = rf_clf.predict_proba(cluster_data.drop('cluster', axis=1))\n",
    "        avg_probs = np.mean(probs, axis=0)\n",
    "        top3 = np.argsort(avg_probs)[-3:][::-1]\n",
    "        print(f'Cluster {cluster} top 3 species: {top3}')\n",
    "\n",
    "# Discussion: Based on clusters, recommend species for regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models\n",
    "\n",
    "Save RF, XGB, KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/Users/godishalarishi/AML-tree/models', exist_ok=True)\n",
    "import joblib\n",
    "joblib.dump(rf_clf, '/Users/godishalarishi/AML-tree/models/rf_model.pkl')\n",
    "joblib.dump(xgb_clf, '/Users/godishalarishi/AML-tree/models/xgb_model.pkl')\n",
    "joblib.dump(kmeans, '/Users/godishalarishi/AML-tree/models/kmeans_model.pkl')\n",
    "print('Models saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
